# 📁 **نظام تحليل الفيديو باستخدام 3D-CNN و Streamlit**

---

## 🌟 **نبذة عن المشروع**
هذا المشروع هو نظام متكامل لتحليل الفيديوهات باستخدام تقنيات الذكاء الاصطناعي. يتكون النظام من ثلاثة أجزاء رئيسية:

1. **تدريب نموذج 3D-CNN**: يتم استخدام دفتر Jupyter (`video-analysis.ipynb`) لتدريب نموذج تصنيف الفيديوهات باستخدام شبكة عصبية تلافيفية ثلاثية الأبعاد (3D-CNN).  
2. **واجهة Streamlit**: تطبيق ويب بسيط يتيح للمستخدمين تحميل ملفات الفيديو وإرسالها إلى خادم **FastAPI** للتحليل.  
3. **خادم FastAPI**: يقوم باستقبال الفيديوهات، معالجتها باستخدام النموذج المُدرَّب، وإرجاع نتائج التحليل.

---

## 🛠️ **المتطلبات الأساسية**
قبل تشغيل المشروع، تأكد من توفر المتطلبات التالية:

### 1. **المكتبات المطلوبة**
- Python 3.x
- Streamlit
- Requests
- FastAPI
- Uvicorn (لتشغيل خادم FastAPI)
- TensorFlow (لتدريب النموذج ومعالجة الفيديوهات)

```bash
pip install streamlit requests fastapi uvicorn tensorflow
```

### 2. **هيكل المشروع**
- **`video-analysis.ipynb`**: دفتر Jupyter يحتوي على الكود الخاص بتدريب نموذج 3D-CNN لتصنيف الفيديوهات.
- **`stremlit-API.py`**: واجهة Streamlit لتحميل الفيديوهات وإرسالها إلى الخادم.
- **`API.py`**: واجهة FastAPI التي تستقبل الفيديوهات وتقوم بالتنبؤ باستخدام النموذج المُدرَّب.

---

## 🚀 **كيف يعمل المشروع؟**

### 1. **تدريب النموذج (video-analysis.ipynb)**
- يتم استخراج الإطارات من الفيديوهات باستخدام دالة `extract_frames`.
- يتم تحويل الإطارات إلى تنسيق مناسب وإدخالها في نموذج 3D-CNN.
- يتم تدريب النموذج باستخدام مجموعة بيانات تحتوي على مقاطع فيديو مصنفة.
- بعد التدريب، يتم حفظ النموذج ليتم استخدامه لاحقًا في التنبؤ.

#### **خطوات التدريب:**
- **استخراج الإطارات**: يتم استخراج عدد ثابت من الإطارات (مثل 16 إطارًا) من كل فيديو.
- **المعالجة المسبقة**: يتم تغيير حجم الإطارات إلى 112x112 بكسل وتحويلها إلى تنسيق NumPy.
- **بناء النموذج**: يتم إنشاء نموذج 3D-CNN متقدم باستخدام طبقات التلافيف الثلاثية الأبعاد (Conv3D) وطبقات التجميع (MaxPooling3D).
- **التدريب**: يتم تدريب النموذج باستخدام بيانات التدريب والتحقق من الصحة.
- **التقييم**: يتم تقييم النموذج باستخدام مجموعة الاختبار وعرض مصفوفة الارتباك وتقرير التصنيف.

---

### 2. **واجهة Streamlit (stremlit-API.py)**
- يتم استخدام **Streamlit** لإنشاء واجهة مستخدم بسيطة تحتوي على:
  - زر لتحميل الفيديو (`mp4`, `avi`, `mov`).
  - زر لإرسال الفيديو إلى خادم FastAPI.
- عند تحميل الفيديو، يتم عرضه مباشرة في الواجهة.
- عند الضغط على زر "Send to API"، يتم إرسال الفيديو إلى الخادم باستخدام طلب HTTP POST.
- يتم عرض نتيجة التنبؤ مباشرة في الواجهة.

---

### 3. **خادم FastAPI (API.py)**
- يستقبل الخادم الفيديوهات المرسلة من واجهة Streamlit.
- يتم معالجة الفيديوهات باستخدام النموذج المُدرَّب (3D-CNN).
- يتم إرجاع نتيجة التنبؤ إلى واجهة Streamlit.

---

## 🔧 **كيفية التشغيل**

### 1. **تشغيل خادم FastAPI**
تأكد من أن لديك ملف النموذج المُدرَّب جاهزًا. ثم قم بتشغيل خادم FastAPI باستخدام الأمر التالي:

```bash
uvicorn API:app --reload
```

### 2. **تشغيل واجهة Streamlit**
قم بتشغيل واجهة Streamlit باستخدام الأمر التالي:

```bash
streamlit run stremlit-API.py
```

### 3. **تحميل الفيديو وتحليله**
- افتح واجهة Streamlit في متصفحك.
- قم بتحميل فيديو باستخدام الزر المخصص.
- اضغط على زر "Send to API" لإرسال الفيديو إلى الخادم.
- ستظهر نتيجة التنبؤ مباشرة في الواجهة.

---

## 🎨 **التخصيص**
### 1. **استخدام كاميرا ويب**
للاستخدام مع كاميرا ويب، يمكنك تعديل الكود ليصبح:
```python
cap = cv2.VideoCapture(0)
```

### 2. **نموذج مختلف**
إذا كنت تريد استخدام نموذج آخر، قم بتغيير اسم الملف:
```python
model = YOLO("your_model.pt")
```

---

## 📸 **عينة من النتائج**
عند تشغيل البرنامج، ستظهر واجهة Streamlit تعرض الفيديو المرفوع مع نتيجة التنبؤ، مثل:
- **Class A: 0.95**: يشير إلى أن الفئة هي "A" مع درجة ثقة 95%.
- **Class B: 0.87**: يشير إلى أن الفئة هي "B" مع درجة ثقة 87%.

---

## 🙏 **شكرًا لك!**
نأمل أن تستمتع باستخدام هذا المشروع البسيط والمفيد! إذا كان لديك أي أسئلة أو اقتراحات، فلا تتردد في التواصل معنا. ✨

--- 

🌟 **Happy Coding!** 🌟
